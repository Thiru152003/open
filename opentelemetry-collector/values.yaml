# Core Configuration
enabled: true
mode: deployment
nameOverride: ""
fullnameOverride: ""
namespaceOverride: "otel-collector"

# Pod Disruption Budget
podDisruptionBudget:
  enabled: true
  minAvailable: 1

# Presets Configuration
presets:
  logsCollection:
    enabled: true
    includeCollectorLogs: false
    storeCheckpoints: false
    maxRecombineLogSize: 102400
  hostMetrics:
    enabled: true
  kubeletMetrics:
    enabled: true
  kubernetesAttributes:
    enabled: true
    extractAllPodLabels: false
    extractAllPodAnnotations: false
  kubernetesEvents:
    enabled: false
  clusterMetrics:
    enabled: false

# ConfigMap Configuration
configMap:
  create: true
  existingName: ""
  existingPath: ""

# Collector Configuration
config:
  extensions:
    health_check: {}
    memory_ballast:
      size_mib: 512

  exporters:
    logging:
      loglevel: debug
    otlp:
      endpoint: "otel-endpoint:4317"
      tls:
        insecure: false
    prometheus:
      endpoint: "0.0.0.0:8889"
    jaeger:
      endpoint: "jaeger-collector.observability.svc.cluster.local:14250"
      tls:
        insecure: true
      retry_on_failure:
        enabled: true
        initial_interval: 5s
        max_interval: 30s
        max_elapsed_time: 120s
      sending_queue:
        enabled: true
        num_consumers: 10
        queue_size: 5000

  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: "0.0.0.0:4317"
        http:
          endpoint: "0.0.0.0:4318"
    prometheus:
      config:
        scrape_configs:
          - job_name: opentelemetry-collector
            scrape_interval: 10s
            static_configs:
              - targets: ["${env:MY_POD_IP}:8888"]
    jaeger:
      protocols:
        grpc:
          endpoint: "0.0.0.0:14250"
        thrift_http:
          endpoint: "0.0.0.0:14268"
        thrift_compact:
          endpoint: "0.0.0.0:6831"
        thrift_binary:
          endpoint: "0.0.0.0:6832"

  processors:
    batch:
      timeout: 5s
      send_batch_size: 10000
    memory_limiter:
      check_interval: 5s
      limit_percentage: 80
      spike_limit_percentage: 25
    resourcedetection:
      detectors: [env, system, gce, ecs, ec2, azure, eks, gke]
      timeout: 5s
      override: false

  service:
    extensions: [health_check, memory_ballast]
    pipelines:
      traces:
        receivers: [otlp, jaeger]
        processors: [memory_limiter, resourcedetection, batch]
        exporters: [logging, jaeger]
      metrics:
        receivers: [otlp, prometheus]
        processors: [memory_limiter, resourcedetection, batch]
        exporters: [logging, prometheus]
      logs:
        receivers: [otlp]
        processors: [memory_limiter, resourcedetection, batch]
        exporters: [logging]

# Image Configuration
image:
  repository: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib
  tag: "0.96.0"
  pullPolicy: IfNotPresent

# Service Account Configuration
serviceAccount:
  create: true
  name: "otel-collector"
  annotations: {}

# RBAC Configuration
rbac:
  create: true
  rules:
    - apiGroups: [""]
      resources: ["pods", "nodes", "nodes/proxy", "services", "endpoints"]
      verbs: ["get", "list", "watch"]
    - apiGroups: ["extensions", "networking.k8s.io"]
      resources: ["ingresses"]
      verbs: ["get", "list", "watch"]
    - nonResourceURLs: ["/metrics"]
      verbs: ["get"]

# Pod Configuration
podSecurityContext:
  fsGroup: 10001
  runAsUser: 10001
  runAsNonRoot: true

securityContext:
  capabilities:
    drop: ["ALL"]
  readOnlyRootFilesystem: true

nodeSelector: {}
tolerations: []
affinity: {}
topologySpreadConstraints: []
priorityClassName: ""

# Environment Configuration
extraEnvs:
  - name: MY_POD_IP
    valueFrom:
      fieldRef:
        fieldPath: status.podIP
  - name: OTEL_RESOURCE_ATTRIBUTES
    value: "k8s.cluster.name=my-cluster,k8s.namespace.name=$(NAMESPACE)"

# Ports Configuration
ports:
  otlp:
    enabled: true
    containerPort: 4317
    servicePort: 4317
    protocol: TCP
  otlp-http:
    enabled: true
    containerPort: 4318
    servicePort: 4318
    protocol: TCP
  metrics:
    enabled: true
    containerPort: 8888
    servicePort: 8888
    protocol: TCP
  jaeger:
    enabled: true
    containerPort: 14250
    servicePort: 14250
    protocol: TCP
  jaeger-thrift-http:
    enabled: true
    containerPort: 14268
    servicePort: 14268
    protocol: TCP
  jaeger-thrift-compact:
    enabled: true
    containerPort: 6831
    servicePort: 6831
    protocol: UDP
  jaeger-thrift-binary:
    enabled: true
    containerPort: 6832
    servicePort: 6832
    protocol: UDP

# Resources Configuration
resources:
  limits:
    cpu: "1000m"
    memory: "2Gi"
  requests:
    cpu: "200m"
    memory: "1Gi"

# Probes Configuration
livenessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 15
  periodSeconds: 10
  timeoutSeconds: 1
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 5
  periodSeconds: 10
  timeoutSeconds: 1
  failureThreshold: 3

startupProbe:
  httpGet:
    path: /
    port: 13133
  failureThreshold: 30
  periodSeconds: 10

# Deployment Configuration
replicaCount: 2
revisionHistoryLimit: 10
annotations: {}

# Service Configuration
service:
  enabled: true
  type: ClusterIP
  annotations: {}
  externalTrafficPolicy: ""
  internalTrafficPolicy: "Cluster"

# Monitoring Configuration
podMonitor:
  enabled: false

serviceMonitor:
  enabled: false

# Prometheus Rules Configuration
prometheusRule:
  enabled: false

# Network Policy Configuration
networkPolicy:
  enabled: false

# Autoscaling Configuration
autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 80

# Additional Configuration
useGOMEMLIMIT: true
shareProcessNamespace: false
